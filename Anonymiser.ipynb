{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anonymiser:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = SequenceTagger.load(\n",
    "            os.getcwd()+'/resources/models/total/bilstm-crf/bert-elmo/best-model.pt')\n",
    "        self.anonymise_mode = 'suppresion'\n",
    "        self.anonymised = []\n",
    "        \n",
    "    def anonymise(self, text):\n",
    "        self.predict_tags(text)\n",
    "        \n",
    "        for t in self.tagged_sentence:\n",
    "            self.anonymised.append(self.suppress(t))\n",
    "    \n",
    "        return self.anonymised\n",
    "    \n",
    "    def predict_tags(self, text):\n",
    "        sentence = Sentence(text)\n",
    "        self.model.predict(sentence)\n",
    "        self.tagged_sentence = sentence\n",
    "        \n",
    "        \n",
    "    def suppress(self, token):\n",
    "        tag = token.get_tag('ner')\n",
    "            \n",
    "        if tag.value == \"O\":\n",
    "            return token.text\n",
    "        else:\n",
    "            return tag.value.split(\"-\")[1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"Mohamed Williams ( MBA - Finance ) Jalan Nakula , Indonesia Mobile : +1 5690234 Email : amylevine@nunez.com With 4 years of professional experience in Fund Accounting ,  Initiation of SOX for \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 10:36:57,071 loading file /Users/bowesdorp/PycharmProjects/Anonymising-Resumes/resources/models/total/bilstm-crf/bert-elmo/best-model.pt\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9a13455e7e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnonymiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0manon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manonymise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-77d2c42fd4c5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         self.model = SequenceTagger.load(\n\u001b[0m\u001b[1;32m      5\u001b[0m             os.getcwd()+'/resources/models/total/bilstm-crf/bert-elmo/best-model.pt')\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manonymise_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'suppresion'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/nn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# see https://github.com/zalandoresearch/flair/issues/351\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_big_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_model_with_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'"
     ]
    }
   ],
   "source": [
    "a = Anonymiser()\n",
    "anon = a.anonymise(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME',\n",
       " 'NAME',\n",
       " '(',\n",
       " 'MBA',\n",
       " '-',\n",
       " 'Finance',\n",
       " ')',\n",
       " 'NAME',\n",
       " 'NAME',\n",
       " 'NAME',\n",
       " 'ADDRESS',\n",
       " 'Mobile',\n",
       " ':',\n",
       " 'PHONE',\n",
       " 'PHONE',\n",
       " 'PHONE',\n",
       " 'Email',\n",
       " ':',\n",
       " 'EMAIL',\n",
       " '@',\n",
       " 'EMAIL',\n",
       " 'With',\n",
       " '4',\n",
       " 'years',\n",
       " 'of',\n",
       " 'professional',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'Fund',\n",
       " 'Accounting',\n",
       " ',',\n",
       " 'Initiation',\n",
       " 'of',\n",
       " 'SOX',\n",
       " 'for']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume = \"Mohamed Williams ( MBA - Finance ) Jalan Nakula , Indonesia Mobile : +1 5690234 Email : amylevine@nunez.com With 4 years of professional experience in Fund Accounting , I have been performing a role of SME ( Subject Matter Expert ) with complete understanding of NAV Calculation for Mutual Funds , Hedge Funds , Private Equity , Real Estate and its related functions like Custody , TA , Pricing , Corporate Actions , etc . Role includes review across all funds and its instrument types . I also ensure all reconciliation breaks in TA , Cash & Stock are validated / justified for each calculated NAV in a timely manner as per SLA . Part of ' NAV Calculation ' team in BNP Paribas which provides Fund Accounting services to internal and third - party funds . Been part of ' Fund Reconciliation ' team which provides support to StateStreet in Hedge Funds Reconciliation . Supporting the client in calculating NAV for their stakeholders . Been part of ' Expense Calculation ' team as well which provides support to StateStreet . EXPERIENCE : Employer Title Date of Employment BNP Paribas , Chennai . Senior Fund Accountant December 2013 – July 2016 StateStreet HCL , Chennai . Financial Analyst November 2012 to November 2013 IT & KEY SKILLS : Multifonds , Intellimatch , Bloomberg , Lotus Notes , Amanda , Spider , Reporting Operation , pContol , Fund Administrator , Pilot , Oracle , Moski , Tally and TM1 . Flexible , self - motivated and work under pressure to tight deadlines . Strong analytical and problem - solving skills . Work effectively both within a team structure and independently . BNP Paribas – Senior Fund Accountant Key Accountabilities of the Role Processing of shareholders activities and trade activities . Preparation of Cash , Positions TA Reconciliations . Preparation and processing of income and expense Accruals . Verification and processing of Corporate Actions . Price portfolios including Equities , Options , Futures , Fixed Income , OTC 's and Forwards Assist in the Audit process and Financial Statement preparation if required . Verification and justification of Pricing and NAV Calculation . Establish and maintain good relationships with internal service departments and clients . Attend and participate in team meetings . Ensure that BNP Paribas ’s client focused ethos is maintained on a daily basis . Adhoc Responsibilities Completeness of NAV packs includes accurate report generation , timely delivery of reports , scanning & archiving . Support in preparation of Key / Standard Operating Procedures for each process migrated to Chennai . Consistently evaluate the documented procedures to ensure they are complete , accurate and up to date and carry out other ad - hoc duties that may arise from time to time , mainly on month ends & year ends . Ensure review of critical queries before sent . When issues / errors arise ensure detailed analysis of issues and clear understanding is gained before responding to client , spoke or other parties . Identifying the staff training requirement & ensure all the necessary training has been provided to the team members to perform the relevant tasks . State Street HCL – Financial Analyst Key Accountabilities of Fund Reconciliation and Expense Calculation Preparation of Cash , Positions and TA Reconciliations Preparation and processing of income and expense Accruals Verification and processing of Corporate Actions Assist in the Audit process and Financial Statement preparation if required Attend and participate in team meetings Ensure that StateStreet ’s client focused ethos is maintained on a daily basis . Initiation of SOX for the amendments of Fund , Class , Manager Launches or terminations . Downloading NAV 's from MCH & uploading to TM1 . Calculation of Fee based on NAV 's and Market Value Analysis of Fee Schedule . Generating Payment Instructions for Clients based on the value date . Achievements Have been awarded Star of the Month , Spot and KAIZEN for performing over and beyond in BNP Paribas Global Securities Operations , Chennai . Education Qualification Board / University Name of the Institute Year of Passing Percentage MBA Anna University CARE School of Business Management , Trichy . 2012 70 B.Com Bharathidasan University Bishop Heber College , Trichy . 2010 83 Personal Information Date of Birth : 29h August , 1983 Marital Status : Single Languages Known : English and Tamil Passport : FK23OP12 Location : Indonesia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 Mohamed\n",
      "Token: 2 Williams\n",
      "Token: 3 (\n",
      "Token: 4 MBA\n",
      "Token: 5 -\n",
      "Token: 6 Finance\n",
      "Token: 7 )\n",
      "Token: 8 Jalan\n",
      "Token: 9 Nakula\n",
      "Token: 10 ,\n",
      "Token: 11 Indonesia\n",
      "Token: 12 Mobile\n",
      "Token: 13 :\n",
      "Token: 14 +\n",
      "Token: 15 1\n",
      "Token: 16 5690234\n",
      "Token: 17 Email\n",
      "Token: 18 :\n",
      "Token: 19 amylevine\n",
      "Token: 20 @\n",
      "Token: 21 nunez.com\n",
      "Token: 22 With\n",
      "Token: 23 4\n",
      "Token: 24 years\n",
      "Token: 25 of\n",
      "Token: 26 professional\n",
      "Token: 27 experience\n",
      "Token: 28 in\n",
      "Token: 29 Fund\n",
      "Token: 30 Accounting\n",
      "Token: 31 ,\n",
      "Token: 32 I\n",
      "Token: 33 have\n",
      "Token: 34 been\n",
      "Token: 35 performing\n",
      "Token: 36 a\n",
      "Token: 37 role\n",
      "Token: 38 of\n",
      "Token: 39 SME\n",
      "Token: 40 (\n",
      "Token: 41 Subject\n",
      "Token: 42 Matter\n",
      "Token: 43 Expert\n",
      "Token: 44 )\n",
      "Token: 45 with\n",
      "Token: 46 complete\n",
      "Token: 47 understanding\n",
      "Token: 48 of\n",
      "Token: 49 NAV\n",
      "Token: 50 Calculation\n",
      "Token: 51 for\n",
      "Token: 52 Mutual\n",
      "Token: 53 Funds\n",
      "Token: 54 ,\n",
      "Token: 55 Hedge\n",
      "Token: 56 Funds\n",
      "Token: 57 ,\n",
      "Token: 58 Private\n",
      "Token: 59 Equity\n",
      "Token: 60 ,\n",
      "Token: 61 Real\n",
      "Token: 62 Estate\n",
      "Token: 63 and\n",
      "Token: 64 its\n",
      "Token: 65 related\n",
      "Token: 66 functions\n",
      "Token: 67 like\n",
      "Token: 68 Custody\n",
      "Token: 69 ,\n",
      "Token: 70 TA\n",
      "Token: 71 ,\n",
      "Token: 72 Pricing\n",
      "Token: 73 ,\n",
      "Token: 74 Corporate\n",
      "Token: 75 Actions\n",
      "Token: 76 ,\n",
      "Token: 77 etc\n",
      "Token: 78 .\n",
      "Token: 79 Role\n",
      "Token: 80 includes\n",
      "Token: 81 review\n",
      "Token: 82 across\n",
      "Token: 83 all\n",
      "Token: 84 funds\n",
      "Token: 85 and\n",
      "Token: 86 its\n",
      "Token: 87 instrument\n",
      "Token: 88 types\n",
      "Token: 89 .\n",
      "Token: 90 I\n",
      "Token: 91 also\n",
      "Token: 92 ensure\n",
      "Token: 93 all\n",
      "Token: 94 reconciliation\n",
      "Token: 95 breaks\n",
      "Token: 96 in\n",
      "Token: 97 TA\n",
      "Token: 98 ,\n",
      "Token: 99 Cash\n",
      "Token: 100 &\n",
      "Token: 101 Stock\n",
      "Token: 102 are\n",
      "Token: 103 validated\n",
      "Token: 104 /\n",
      "Token: 105 justified\n",
      "Token: 106 for\n",
      "Token: 107 each\n",
      "Token: 108 calculated\n",
      "Token: 109 NAV\n",
      "Token: 110 in\n",
      "Token: 111 a\n",
      "Token: 112 timely\n",
      "Token: 113 manner\n",
      "Token: 114 as\n",
      "Token: 115 per\n",
      "Token: 116 SLA\n",
      "Token: 117 .\n",
      "Token: 118 Part\n",
      "Token: 119 of\n",
      "Token: 120 '\n",
      "Token: 121 NAV\n",
      "Token: 122 Calculation\n",
      "Token: 123 '\n",
      "Token: 124 team\n",
      "Token: 125 in\n",
      "Token: 126 BNP\n",
      "Token: 127 Paribas\n",
      "Token: 128 which\n",
      "Token: 129 provides\n",
      "Token: 130 Fund\n",
      "Token: 131 Accounting\n",
      "Token: 132 services\n",
      "Token: 133 to\n",
      "Token: 134 internal\n",
      "Token: 135 and\n",
      "Token: 136 third\n",
      "Token: 137 -\n",
      "Token: 138 party\n",
      "Token: 139 funds\n",
      "Token: 140 .\n",
      "Token: 141 Been\n",
      "Token: 142 part\n",
      "Token: 143 of\n",
      "Token: 144 '\n",
      "Token: 145 Fund\n",
      "Token: 146 Reconciliation\n",
      "Token: 147 '\n",
      "Token: 148 team\n",
      "Token: 149 which\n",
      "Token: 150 provides\n",
      "Token: 151 support\n",
      "Token: 152 to\n",
      "Token: 153 StateStreet\n",
      "Token: 154 in\n",
      "Token: 155 Hedge\n",
      "Token: 156 Funds\n",
      "Token: 157 Reconciliation\n",
      "Token: 158 .\n",
      "Token: 159 Supporting\n",
      "Token: 160 the\n",
      "Token: 161 client\n",
      "Token: 162 in\n",
      "Token: 163 calculating\n",
      "Token: 164 NAV\n",
      "Token: 165 for\n",
      "Token: 166 their\n",
      "Token: 167 stakeholders\n",
      "Token: 168 .\n",
      "Token: 169 Been\n",
      "Token: 170 part\n",
      "Token: 171 of\n",
      "Token: 172 '\n",
      "Token: 173 Expense\n",
      "Token: 174 Calculation\n",
      "Token: 175 '\n",
      "Token: 176 team\n",
      "Token: 177 as\n",
      "Token: 178 well\n",
      "Token: 179 which\n",
      "Token: 180 provides\n",
      "Token: 181 support\n",
      "Token: 182 to\n",
      "Token: 183 StateStreet\n",
      "Token: 184 .\n",
      "Token: 185 EXPERIENCE\n",
      "Token: 186 :\n",
      "Token: 187 Employer\n",
      "Token: 188 Title\n",
      "Token: 189 Date\n",
      "Token: 190 of\n",
      "Token: 191 Employment\n",
      "Token: 192 BNP\n",
      "Token: 193 Paribas\n",
      "Token: 194 ,\n",
      "Token: 195 Chennai\n",
      "Token: 196 .\n",
      "Token: 197 Senior\n",
      "Token: 198 Fund\n",
      "Token: 199 Accountant\n",
      "Token: 200 December\n",
      "Token: 201 2013\n",
      "Token: 202 –\n",
      "Token: 203 July\n",
      "Token: 204 2016\n",
      "Token: 205 StateStreet\n",
      "Token: 206 HCL\n",
      "Token: 207 ,\n",
      "Token: 208 Chennai\n",
      "Token: 209 .\n",
      "Token: 210 Financial\n",
      "Token: 211 Analyst\n",
      "Token: 212 November\n",
      "Token: 213 2012\n",
      "Token: 214 to\n",
      "Token: 215 November\n",
      "Token: 216 2013\n",
      "Token: 217 IT\n",
      "Token: 218 &\n",
      "Token: 219 KEY\n",
      "Token: 220 SKILLS\n",
      "Token: 221 :\n",
      "Token: 222 Multifonds\n",
      "Token: 223 ,\n",
      "Token: 224 Intellimatch\n",
      "Token: 225 ,\n",
      "Token: 226 Bloomberg\n",
      "Token: 227 ,\n",
      "Token: 228 Lotus\n",
      "Token: 229 Notes\n",
      "Token: 230 ,\n",
      "Token: 231 Amanda\n",
      "Token: 232 ,\n",
      "Token: 233 Spider\n",
      "Token: 234 ,\n",
      "Token: 235 Reporting\n",
      "Token: 236 Operation\n",
      "Token: 237 ,\n",
      "Token: 238 pContol\n",
      "Token: 239 ,\n",
      "Token: 240 Fund\n",
      "Token: 241 Administrator\n",
      "Token: 242 ,\n",
      "Token: 243 Pilot\n",
      "Token: 244 ,\n",
      "Token: 245 Oracle\n",
      "Token: 246 ,\n",
      "Token: 247 Moski\n",
      "Token: 248 ,\n",
      "Token: 249 Tally\n",
      "Token: 250 and\n",
      "Token: 251 TM1\n",
      "Token: 252 .\n",
      "Token: 253 Flexible\n",
      "Token: 254 ,\n",
      "Token: 255 self\n",
      "Token: 256 -\n",
      "Token: 257 motivated\n",
      "Token: 258 and\n",
      "Token: 259 work\n",
      "Token: 260 under\n",
      "Token: 261 pressure\n",
      "Token: 262 to\n",
      "Token: 263 tight\n",
      "Token: 264 deadlines\n",
      "Token: 265 .\n",
      "Token: 266 Strong\n",
      "Token: 267 analytical\n",
      "Token: 268 and\n",
      "Token: 269 problem\n",
      "Token: 270 -\n",
      "Token: 271 solving\n",
      "Token: 272 skills\n",
      "Token: 273 .\n",
      "Token: 274 Work\n",
      "Token: 275 effectively\n",
      "Token: 276 both\n",
      "Token: 277 within\n",
      "Token: 278 a\n",
      "Token: 279 team\n",
      "Token: 280 structure\n",
      "Token: 281 and\n",
      "Token: 282 independently\n",
      "Token: 283 .\n",
      "Token: 284 BNP\n",
      "Token: 285 Paribas\n",
      "Token: 286 –\n",
      "Token: 287 Senior\n",
      "Token: 288 Fund\n",
      "Token: 289 Accountant\n",
      "Token: 290 Key\n",
      "Token: 291 Accountabilities\n",
      "Token: 292 of\n",
      "Token: 293 the\n",
      "Token: 294 Role\n",
      "Token: 295 Processing\n",
      "Token: 296 of\n",
      "Token: 297 shareholders\n",
      "Token: 298 activities\n",
      "Token: 299 and\n",
      "Token: 300 trade\n",
      "Token: 301 activities\n",
      "Token: 302 .\n",
      "Token: 303 Preparation\n",
      "Token: 304 of\n",
      "Token: 305 Cash\n",
      "Token: 306 ,\n",
      "Token: 307 Positions\n",
      "Token: 308 TA\n",
      "Token: 309 Reconciliations\n",
      "Token: 310 .\n",
      "Token: 311 Preparation\n",
      "Token: 312 and\n",
      "Token: 313 processing\n",
      "Token: 314 of\n",
      "Token: 315 income\n",
      "Token: 316 and\n",
      "Token: 317 expense\n",
      "Token: 318 Accruals\n",
      "Token: 319 .\n",
      "Token: 320 Verification\n",
      "Token: 321 and\n",
      "Token: 322 processing\n",
      "Token: 323 of\n",
      "Token: 324 Corporate\n",
      "Token: 325 Actions\n",
      "Token: 326 .\n",
      "Token: 327 Price\n",
      "Token: 328 portfolios\n",
      "Token: 329 including\n",
      "Token: 330 Equities\n",
      "Token: 331 ,\n",
      "Token: 332 Options\n",
      "Token: 333 ,\n",
      "Token: 334 Futures\n",
      "Token: 335 ,\n",
      "Token: 336 Fixed\n",
      "Token: 337 Income\n",
      "Token: 338 ,\n",
      "Token: 339 OTC\n",
      "Token: 340 '\n",
      "Token: 341 s\n",
      "Token: 342 and\n",
      "Token: 343 Forwards\n",
      "Token: 344 Assist\n",
      "Token: 345 in\n",
      "Token: 346 the\n",
      "Token: 347 Audit\n",
      "Token: 348 process\n",
      "Token: 349 and\n",
      "Token: 350 Financial\n",
      "Token: 351 Statement\n",
      "Token: 352 preparation\n",
      "Token: 353 if\n",
      "Token: 354 required\n",
      "Token: 355 .\n",
      "Token: 356 Verification\n",
      "Token: 357 and\n",
      "Token: 358 justification\n",
      "Token: 359 of\n",
      "Token: 360 Pricing\n",
      "Token: 361 and\n",
      "Token: 362 NAV\n",
      "Token: 363 Calculation\n",
      "Token: 364 .\n",
      "Token: 365 Establish\n",
      "Token: 366 and\n",
      "Token: 367 maintain\n",
      "Token: 368 good\n",
      "Token: 369 relationships\n",
      "Token: 370 with\n",
      "Token: 371 internal\n",
      "Token: 372 service\n",
      "Token: 373 departments\n",
      "Token: 374 and\n",
      "Token: 375 clients\n",
      "Token: 376 .\n",
      "Token: 377 Attend\n",
      "Token: 378 and\n",
      "Token: 379 participate\n",
      "Token: 380 in\n",
      "Token: 381 team\n",
      "Token: 382 meetings\n",
      "Token: 383 .\n",
      "Token: 384 Ensure\n",
      "Token: 385 that\n",
      "Token: 386 BNP\n",
      "Token: 387 Paribas\n",
      "Token: 388 ’s\n",
      "Token: 389 client\n",
      "Token: 390 focused\n",
      "Token: 391 ethos\n",
      "Token: 392 is\n",
      "Token: 393 maintained\n",
      "Token: 394 on\n",
      "Token: 395 a\n",
      "Token: 396 daily\n",
      "Token: 397 basis\n",
      "Token: 398 .\n",
      "Token: 399 Adhoc\n",
      "Token: 400 Responsibilities\n",
      "Token: 401 Completeness\n",
      "Token: 402 of\n",
      "Token: 403 NAV\n",
      "Token: 404 packs\n",
      "Token: 405 includes\n",
      "Token: 406 accurate\n",
      "Token: 407 report\n",
      "Token: 408 generation\n",
      "Token: 409 ,\n",
      "Token: 410 timely\n",
      "Token: 411 delivery\n",
      "Token: 412 of\n",
      "Token: 413 reports\n",
      "Token: 414 ,\n",
      "Token: 415 scanning\n",
      "Token: 416 &\n",
      "Token: 417 archiving\n",
      "Token: 418 .\n",
      "Token: 419 Support\n",
      "Token: 420 in\n",
      "Token: 421 preparation\n",
      "Token: 422 of\n",
      "Token: 423 Key\n",
      "Token: 424 /\n",
      "Token: 425 Standard\n",
      "Token: 426 Operating\n",
      "Token: 427 Procedures\n",
      "Token: 428 for\n",
      "Token: 429 each\n",
      "Token: 430 process\n",
      "Token: 431 migrated\n",
      "Token: 432 to\n",
      "Token: 433 Chennai\n",
      "Token: 434 .\n",
      "Token: 435 Consistently\n",
      "Token: 436 evaluate\n",
      "Token: 437 the\n",
      "Token: 438 documented\n",
      "Token: 439 procedures\n",
      "Token: 440 to\n",
      "Token: 441 ensure\n",
      "Token: 442 they\n",
      "Token: 443 are\n",
      "Token: 444 complete\n",
      "Token: 445 ,\n",
      "Token: 446 accurate\n",
      "Token: 447 and\n",
      "Token: 448 up\n",
      "Token: 449 to\n",
      "Token: 450 date\n",
      "Token: 451 and\n",
      "Token: 452 carry\n",
      "Token: 453 out\n",
      "Token: 454 other\n",
      "Token: 455 ad\n",
      "Token: 456 -\n",
      "Token: 457 hoc\n",
      "Token: 458 duties\n",
      "Token: 459 that\n",
      "Token: 460 may\n",
      "Token: 461 arise\n",
      "Token: 462 from\n",
      "Token: 463 time\n",
      "Token: 464 to\n",
      "Token: 465 time\n",
      "Token: 466 ,\n",
      "Token: 467 mainly\n",
      "Token: 468 on\n",
      "Token: 469 month\n",
      "Token: 470 ends\n",
      "Token: 471 &\n",
      "Token: 472 year\n",
      "Token: 473 ends\n",
      "Token: 474 .\n",
      "Token: 475 Ensure\n",
      "Token: 476 review\n",
      "Token: 477 of\n",
      "Token: 478 critical\n",
      "Token: 479 queries\n",
      "Token: 480 before\n",
      "Token: 481 sent\n",
      "Token: 482 .\n",
      "Token: 483 When\n",
      "Token: 484 issues\n",
      "Token: 485 /\n",
      "Token: 486 errors\n",
      "Token: 487 arise\n",
      "Token: 488 ensure\n",
      "Token: 489 detailed\n",
      "Token: 490 analysis\n",
      "Token: 491 of\n",
      "Token: 492 issues\n",
      "Token: 493 and\n",
      "Token: 494 clear\n",
      "Token: 495 understanding\n",
      "Token: 496 is\n",
      "Token: 497 gained\n",
      "Token: 498 before\n",
      "Token: 499 responding\n",
      "Token: 500 to\n",
      "Token: 501 client\n",
      "Token: 502 ,\n",
      "Token: 503 spoke\n",
      "Token: 504 or\n",
      "Token: 505 other\n",
      "Token: 506 parties\n",
      "Token: 507 .\n",
      "Token: 508 Identifying\n",
      "Token: 509 the\n",
      "Token: 510 staff\n",
      "Token: 511 training\n",
      "Token: 512 requirement\n",
      "Token: 513 &\n",
      "Token: 514 ensure\n",
      "Token: 515 all\n",
      "Token: 516 the\n",
      "Token: 517 necessary\n",
      "Token: 518 training\n",
      "Token: 519 has\n",
      "Token: 520 been\n",
      "Token: 521 provided\n",
      "Token: 522 to\n",
      "Token: 523 the\n",
      "Token: 524 team\n",
      "Token: 525 members\n",
      "Token: 526 to\n",
      "Token: 527 perform\n",
      "Token: 528 the\n",
      "Token: 529 relevant\n",
      "Token: 530 tasks\n",
      "Token: 531 .\n",
      "Token: 532 State\n",
      "Token: 533 Street\n",
      "Token: 534 HCL\n",
      "Token: 535 –\n",
      "Token: 536 Financial\n",
      "Token: 537 Analyst\n",
      "Token: 538 Key\n",
      "Token: 539 Accountabilities\n",
      "Token: 540 of\n",
      "Token: 541 Fund\n",
      "Token: 542 Reconciliation\n",
      "Token: 543 and\n",
      "Token: 544 Expense\n",
      "Token: 545 Calculation\n",
      "Token: 546 Preparation\n",
      "Token: 547 of\n",
      "Token: 548 Cash\n",
      "Token: 549 ,\n",
      "Token: 550 Positions\n",
      "Token: 551 and\n",
      "Token: 552 TA\n",
      "Token: 553 Reconciliations\n",
      "Token: 554 Preparation\n",
      "Token: 555 and\n",
      "Token: 556 processing\n",
      "Token: 557 of\n",
      "Token: 558 income\n",
      "Token: 559 and\n",
      "Token: 560 expense\n",
      "Token: 561 Accruals\n",
      "Token: 562 Verification\n",
      "Token: 563 and\n",
      "Token: 564 processing\n",
      "Token: 565 of\n",
      "Token: 566 Corporate\n",
      "Token: 567 Actions\n",
      "Token: 568 Assist\n",
      "Token: 569 in\n",
      "Token: 570 the\n",
      "Token: 571 Audit\n",
      "Token: 572 process\n",
      "Token: 573 and\n",
      "Token: 574 Financial\n",
      "Token: 575 Statement\n",
      "Token: 576 preparation\n",
      "Token: 577 if\n",
      "Token: 578 required\n",
      "Token: 579 Attend\n",
      "Token: 580 and\n",
      "Token: 581 participate\n",
      "Token: 582 in\n",
      "Token: 583 team\n",
      "Token: 584 meetings\n",
      "Token: 585 Ensure\n",
      "Token: 586 that\n",
      "Token: 587 StateStreet\n",
      "Token: 588 ’s\n",
      "Token: 589 client\n",
      "Token: 590 focused\n",
      "Token: 591 ethos\n",
      "Token: 592 is\n",
      "Token: 593 maintained\n",
      "Token: 594 on\n",
      "Token: 595 a\n",
      "Token: 596 daily\n",
      "Token: 597 basis\n",
      "Token: 598 .\n",
      "Token: 599 Initiation\n",
      "Token: 600 of\n",
      "Token: 601 SOX\n",
      "Token: 602 for\n",
      "Token: 603 the\n",
      "Token: 604 amendments\n",
      "Token: 605 of\n",
      "Token: 606 Fund\n",
      "Token: 607 ,\n",
      "Token: 608 Class\n",
      "Token: 609 ,\n",
      "Token: 610 Manager\n",
      "Token: 611 Launches\n",
      "Token: 612 or\n",
      "Token: 613 terminations\n",
      "Token: 614 .\n",
      "Token: 615 Downloading\n",
      "Token: 616 NAV\n",
      "Token: 617 '\n",
      "Token: 618 s\n",
      "Token: 619 from\n",
      "Token: 620 MCH\n",
      "Token: 621 &\n",
      "Token: 622 uploading\n",
      "Token: 623 to\n",
      "Token: 624 TM1\n",
      "Token: 625 .\n",
      "Token: 626 Calculation\n",
      "Token: 627 of\n",
      "Token: 628 Fee\n",
      "Token: 629 based\n",
      "Token: 630 on\n",
      "Token: 631 NAV\n",
      "Token: 632 '\n",
      "Token: 633 s\n",
      "Token: 634 and\n",
      "Token: 635 Market\n",
      "Token: 636 Value\n",
      "Token: 637 Analysis\n",
      "Token: 638 of\n",
      "Token: 639 Fee\n",
      "Token: 640 Schedule\n",
      "Token: 641 .\n",
      "Token: 642 Generating\n",
      "Token: 643 Payment\n",
      "Token: 644 Instructions\n",
      "Token: 645 for\n",
      "Token: 646 Clients\n",
      "Token: 647 based\n",
      "Token: 648 on\n",
      "Token: 649 the\n",
      "Token: 650 value\n",
      "Token: 651 date\n",
      "Token: 652 .\n",
      "Token: 653 Achievements\n",
      "Token: 654 Have\n",
      "Token: 655 been\n",
      "Token: 656 awarded\n",
      "Token: 657 Star\n",
      "Token: 658 of\n",
      "Token: 659 the\n",
      "Token: 660 Month\n",
      "Token: 661 ,\n",
      "Token: 662 Spot\n",
      "Token: 663 and\n",
      "Token: 664 KAIZEN\n",
      "Token: 665 for\n",
      "Token: 666 performing\n",
      "Token: 667 over\n",
      "Token: 668 and\n",
      "Token: 669 beyond\n",
      "Token: 670 in\n",
      "Token: 671 BNP\n",
      "Token: 672 Paribas\n",
      "Token: 673 Global\n",
      "Token: 674 Securities\n",
      "Token: 675 Operations\n",
      "Token: 676 ,\n",
      "Token: 677 Chennai\n",
      "Token: 678 .\n",
      "Token: 679 Education\n",
      "Token: 680 Qualification\n",
      "Token: 681 Board\n",
      "Token: 682 /\n",
      "Token: 683 University\n",
      "Token: 684 Name\n",
      "Token: 685 of\n",
      "Token: 686 the\n",
      "Token: 687 Institute\n",
      "Token: 688 Year\n",
      "Token: 689 of\n",
      "Token: 690 Passing\n",
      "Token: 691 Percentage\n",
      "Token: 692 MBA\n",
      "Token: 693 Anna\n",
      "Token: 694 University\n",
      "Token: 695 CARE\n",
      "Token: 696 School\n",
      "Token: 697 of\n",
      "Token: 698 Business\n",
      "Token: 699 Management\n",
      "Token: 700 ,\n",
      "Token: 701 Trichy\n",
      "Token: 702 .\n",
      "Token: 703 2012\n",
      "Token: 704 70\n",
      "Token: 705 B.Com\n",
      "Token: 706 Bharathidasan\n",
      "Token: 707 University\n",
      "Token: 708 Bishop\n",
      "Token: 709 Heber\n",
      "Token: 710 College\n",
      "Token: 711 ,\n",
      "Token: 712 Trichy\n",
      "Token: 713 .\n",
      "Token: 714 2010\n",
      "Token: 715 83\n",
      "Token: 716 Personal\n",
      "Token: 717 Information\n",
      "Token: 718 Date\n",
      "Token: 719 of\n",
      "Token: 720 Birth\n",
      "Token: 721 :\n",
      "Token: 722 29h\n",
      "Token: 723 August\n",
      "Token: 724 ,\n",
      "Token: 725 1983\n",
      "Token: 726 Marital\n",
      "Token: 727 Status\n",
      "Token: 728 :\n",
      "Token: 729 Single\n",
      "Token: 730 Languages\n",
      "Token: 731 Known\n",
      "Token: 732 :\n",
      "Token: 733 English\n",
      "Token: 734 and\n",
      "Token: 735 Tamil\n",
      "Token: 736 Passport\n",
      "Token: 737 :\n",
      "Token: 738 FK23OP12\n",
      "Token: 739 Location\n",
      "Token: 740 :\n",
      "Token: 741 Indonesia\n"
     ]
    }
   ],
   "source": [
    "a.suppress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
