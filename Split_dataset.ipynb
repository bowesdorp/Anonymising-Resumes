{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm, trange\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_id</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>Name</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>Tan</td>\n",
       "      <td>B-NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>Gang</td>\n",
       "      <td>I-NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Lun</td>\n",
       "      <td>I-NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>105</td>\n",
       "      <td>2010</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>105</td>\n",
       "      <td>CIP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>105</td>\n",
       "      <td>Gold</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>105</td>\n",
       "      <td>Award</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>105</td>\n",
       "      <td>2009</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    File_id   Word     Tag\n",
       "0       105   Name       O\n",
       "1       105      :       O\n",
       "2       105    Tan  B-NAME\n",
       "3       105   Gang  I-NAME\n",
       "4       105    Lun  I-NAME\n",
       "..      ...    ...     ...\n",
       "95      105   2010       O\n",
       "96      105    CIP       O\n",
       "97      105   Gold       O\n",
       "98      105  Award       O\n",
       "99      105   2009       O\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/final/dataset.csv', encoding=\"latin1\")\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "class DocumentGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.documents = self.data.groupby(\"File_id\").apply(agg_func)\n",
    "        \n",
    "        \n",
    "        self.train_size = 0.8\n",
    "        self.test_size = 0.1\n",
    "        self.dev_size = 0.1\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"{}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def split_docs(self):\n",
    "        df = shuffle(self.documents)\n",
    "        \n",
    "        train_size = round(0.8 * len(df))\n",
    "        self.tr_documents = df[:train_size]\n",
    "                           \n",
    "        test_size = round(train_size + (0.1 * len(df)))\n",
    "        self.te_documents = df[train_size:test_size]\n",
    "        \n",
    "        self.de_documents = df[test_size:len(df)]\n",
    "        \n",
    "    def dict_to_df(self, d):\n",
    "        ids = []\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for key in d:\n",
    "            doc = d[key]\n",
    "            \n",
    "            for (token, tag) in doc:\n",
    "                ids.append(key)\n",
    "                tokens.append(token)\n",
    "                tags.append(tag)\n",
    "        \n",
    "        data = {\n",
    "            'File_id': ids,\n",
    "            'Word': tokens,\n",
    "            'Tag': tags\n",
    "        }\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    def create_files(self):\n",
    "        \n",
    "        df_tr = self.dict_to_df(dict(self.tr_documents))\n",
    "        df_te = self.dict_to_df(dict(self.te_documents))\n",
    "        df_de = self.dict_to_df(dict(self.de_documents))\n",
    "        \n",
    "        \n",
    "        print('Train', len(Counter(df_tr['Tag'].values)))\n",
    "        print('Test', len(Counter(df_te['Tag'].values)), Counter(df_te['Tag'].values))\n",
    "        print('Dev', len(Counter(df_de['Tag'].values)), Counter(df_de['Tag'].values))\n",
    "        df_tr.to_csv('./data/final/train.csv', index=False)\n",
    "        df_te.to_csv('./data/final/test.csv', index=False)\n",
    "        df_de.to_csv('./data/final/dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 16\n",
      "Test 14 Counter({'O': 17394, 'I-ADDRESS': 67, 'I-PHONE': 33, 'I-NAME': 30, 'B-NAME': 24, 'B-PHONE': 21, 'B-EMAIL': 19, 'B-ADDRESS': 11, 'I-DOB': 10, 'B-NATIONALITY': 8, 'B-DOB': 5, 'B-GENDER': 5, 'B-AGE': 3, 'B-ETHNICITY': 3})\n",
      "Dev 15 Counter({'O': 16394, 'I-ADDRESS': 79, 'I-PHONE': 32, 'I-NAME': 23, 'B-NAME': 21, 'B-PHONE': 20, 'B-EMAIL': 20, 'B-ADDRESS': 14, 'I-DOB': 11, 'B-DOB': 7, 'B-NATIONALITY': 7, 'B-AGE': 4, 'B-GENDER': 3, 'B-RELIGION': 1, 'B-ETHNICITY': 1})\n"
     ]
    }
   ],
   "source": [
    "doc_Getter = DocumentGetter(df)\n",
    "doc_Getter.split_docs()\n",
    "doc_Getter.create_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(t, s_len, n_dataset):\n",
    "    f_path = './data/final/' + t + '.csv'\n",
    "    d = prepare_data(f_path, s_len)\n",
    "    getter = SentenceGetter(d)\n",
    "    sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
    "    labels = [[s[1] for s in sentence] for sentence in getter.sentences]\n",
    "    \n",
    "    c = list(zip(sentences, labels))\n",
    "    random.shuffle(c)\n",
    "    sentences, labels = zip(*c)\n",
    "    \n",
    "    SIZE = 1\n",
    "    \n",
    "    split = round(len(sentences)*SIZE)\n",
    "    print(len(sentences), len(labels))\n",
    "    sentences = sentences[:split]\n",
    "    labels = labels[:split]\n",
    "    \n",
    "    print(len(sentences), len(labels))\n",
    "    create_txt_file(sentences, labels, t, s_len, n_dataset)\n",
    "    \n",
    "    \n",
    "def prepare_data(file_path, s_len):\n",
    "    # load dataframe\n",
    "    df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "    \n",
    "    # drop nan\n",
    "    df = df.dropna()\n",
    "    \n",
    "    padding_length = 4\n",
    "    sentence_length = s_len\n",
    "    splits = split_in_sentences(sentence_length, padding_length, df)\n",
    "    output = filter_splits(splits, False)\n",
    "    output['Word'] = output['Word']\n",
    "    output = output.dropna()\n",
    "    return output\n",
    "\n",
    "\n",
    "def filter_splits(d, f=True):\n",
    "    if f:\n",
    "        split_tag = d.groupby('Split #')['Tag'].apply(list)\n",
    "        to_remove = []\n",
    "        for key, value in split_tag.items():\n",
    "            tags_in_split = list(set(value))\n",
    "            if len(tags_in_split) == 1 and tags_in_split[0] == 'O':\n",
    "                d = d[d['Split #'] != key]\n",
    "        \n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "def split_in_sentences(sen_len, pad_len, d):\n",
    "    doc_words = d.groupby('File_id')['Word'].apply(list)\n",
    "    doc_tags = d.groupby('File_id')['Tag'].apply(list)\n",
    "    \n",
    "    splits = []\n",
    "    cur_counter = 0\n",
    "    \n",
    "    for i in range(len(doc_words)):\n",
    "        cur_doc = list(doc_words)[i]\n",
    "        cur_tags = list(doc_tags)[i]\n",
    "        cur_counter += 1\n",
    "        for j in range(len(cur_doc)):\n",
    "            splits.append('split ' + str(cur_counter))\n",
    "            if ((j % sen_len) == 0 and j != 0):\n",
    "                    \n",
    "                cur_counter += 1\n",
    "                \n",
    "    d['Split #'] = splits\n",
    "    return d\n",
    "\n",
    "def create_txt_file(s, l, name, s_len, n_dataset):\n",
    "    if (len(s) != len(l)):\n",
    "        print('Not the same length')\n",
    "        return\n",
    "    \n",
    "    f = open('./data/final/s_' +str(s_len)+ '/' + n_dataset + '/' + name +'.txt',\"w+\")\n",
    "    for i in range(len(s)):\n",
    "        sentence = s[i]\n",
    "        labels = l[i]\n",
    "        for j in range(len(sentence)):\n",
    "            \n",
    "            if (is_ascii(sentence[j])):\n",
    "                f.write(sentence[j].strip() + ' ' + labels[j] +'\\n')            \n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "    \n",
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        \n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Split #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"{}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create txt files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LENGTHS = [25, 50, 75, 100, 150, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 16\n",
      "Test 14 Counter({'O': 15864, 'I-ADDRESS': 58, 'I-PHONE': 53, 'I-NAME': 26, 'B-NAME': 23, 'B-PHONE': 23, 'B-EMAIL': 21, 'I-DOB': 14, 'B-ADDRESS': 10, 'B-NATIONALITY': 9, 'B-DOB': 6, 'B-GENDER': 5, 'B-AGE': 2, 'B-ETHNICITY': 1})\n",
      "Dev 15 Counter({'O': 11928, 'I-ADDRESS': 75, 'I-PHONE': 59, 'I-NAME': 22, 'B-NAME': 20, 'B-PHONE': 20, 'B-EMAIL': 18, 'B-ADDRESS': 12, 'B-DOB': 6, 'I-DOB': 6, 'B-NATIONALITY': 5, 'B-AGE': 3, 'B-GENDER': 3, 'B-ETHNICITY': 2, 'B-RELIGION': 1})\n",
      "5340 5340\n",
      "5340 5340\n",
      "654 654\n",
      "654 654\n",
      "496 496\n",
      "496 496\n",
      "2713 2713\n",
      "2713 2713\n",
      "332 332\n",
      "332 332\n",
      "253 253\n",
      "253 253\n",
      "1833 1833\n",
      "1833 1833\n",
      "225 225\n",
      "225 225\n",
      "172 172\n",
      "172 172\n",
      "1398 1398\n",
      "1398 1398\n",
      "172 172\n",
      "172 172\n",
      "131 131\n",
      "131 131\n",
      "956 956\n",
      "956 956\n",
      "117 117\n",
      "117 117\n",
      "92 92\n",
      "92 92\n",
      "739 739\n",
      "739 739\n",
      "90 90\n",
      "90 90\n",
      "70 70\n",
      "70 70\n",
      "Train 16\n",
      "Test 14 Counter({'O': 13471, 'I-ADDRESS': 58, 'I-PHONE': 52, 'I-NAME': 22, 'B-PHONE': 22, 'B-NAME': 21, 'B-EMAIL': 20, 'B-ADDRESS': 10, 'I-DOB': 6, 'B-DOB': 5, 'B-NATIONALITY': 5, 'B-GENDER': 2, 'B-RELIGION': 1, 'B-AGE': 1})\n",
      "Dev 13 Counter({'O': 15510, 'I-ADDRESS': 48, 'I-PHONE': 46, 'I-NAME': 23, 'B-PHONE': 22, 'B-NAME': 21, 'B-EMAIL': 20, 'I-DOB': 10, 'B-ADDRESS': 10, 'B-NATIONALITY': 7, 'B-DOB': 5, 'B-ETHNICITY': 1, 'B-GENDER': 1})\n",
      "5295 5295\n",
      "5295 5295\n",
      "556 556\n",
      "556 556\n",
      "639 639\n",
      "639 639\n",
      "2690 2690\n",
      "2690 2690\n",
      "283 283\n",
      "283 283\n",
      "325 325\n",
      "325 325\n",
      "1817 1817\n",
      "1817 1817\n",
      "194 194\n",
      "194 194\n",
      "219 219\n",
      "219 219\n",
      "1387 1387\n",
      "1387 1387\n",
      "147 147\n",
      "147 147\n",
      "167 167\n",
      "167 167\n",
      "948 948\n",
      "948 948\n",
      "102 102\n",
      "102 102\n",
      "115 115\n",
      "115 115\n",
      "732 732\n",
      "732 732\n",
      "77 77\n",
      "77 77\n",
      "90 90\n",
      "90 90\n",
      "Train 16\n",
      "Test 13 Counter({'O': 14043, 'I-ADDRESS': 57, 'I-PHONE': 43, 'I-NAME': 22, 'B-NAME': 21, 'B-EMAIL': 20, 'B-PHONE': 20, 'I-DOB': 12, 'B-ADDRESS': 11, 'B-DOB': 6, 'B-NATIONALITY': 5, 'B-AGE': 4, 'B-GENDER': 3})\n",
      "Dev 14 Counter({'O': 15221, 'I-ADDRESS': 61, 'I-PHONE': 41, 'I-NAME': 24, 'B-NAME': 23, 'B-PHONE': 22, 'B-EMAIL': 21, 'B-ADDRESS': 11, 'I-DOB': 5, 'B-NATIONALITY': 5, 'B-DOB': 3, 'B-AGE': 1, 'B-ETHNICITY': 1, 'B-GENDER': 1})\n",
      "5284 5284\n",
      "5284 5284\n",
      "579 579\n",
      "579 579\n",
      "627 627\n",
      "627 627\n",
      "2685 2685\n",
      "2685 2685\n",
      "294 294\n",
      "294 294\n",
      "319 319\n",
      "319 319\n",
      "1817 1817\n",
      "1817 1817\n",
      "197 197\n",
      "197 197\n",
      "216 216\n",
      "216 216\n",
      "1382 1382\n",
      "1382 1382\n",
      "153 153\n",
      "153 153\n",
      "166 166\n",
      "166 166\n",
      "949 949\n",
      "949 949\n",
      "103 103\n",
      "103 103\n",
      "113 113\n",
      "113 113\n",
      "729 729\n",
      "729 729\n",
      "81 81\n",
      "81 81\n",
      "89 89\n",
      "89 89\n",
      "Train 16\n",
      "Test 13 Counter({'O': 18783, 'I-ADDRESS': 58, 'I-PHONE': 33, 'B-NAME': 25, 'I-NAME': 24, 'B-PHONE': 19, 'B-EMAIL': 18, 'B-ADDRESS': 10, 'I-DOB': 6, 'B-NATIONALITY': 5, 'B-DOB': 3, 'B-GENDER': 3, 'B-AGE': 1})\n",
      "Dev 13 Counter({'O': 14957, 'I-ADDRESS': 80, 'I-PHONE': 49, 'I-NAME': 42, 'B-NAME': 29, 'B-PHONE': 29, 'B-EMAIL': 22, 'I-DOB': 15, 'B-ADDRESS': 11, 'B-DOB': 7, 'B-NATIONALITY': 4, 'B-GENDER': 3, 'B-ETHNICITY': 1})\n",
      "5102 5102\n",
      "5102 5102\n",
      "769 769\n",
      "769 769\n",
      "619 619\n",
      "619 619\n",
      "2594 2594\n",
      "2594 2594\n",
      "389 389\n",
      "389 389\n",
      "315 315\n",
      "315 315\n",
      "1754 1754\n",
      "1754 1754\n",
      "264 264\n",
      "264 264\n",
      "212 212\n",
      "212 212\n",
      "1341 1341\n",
      "1341 1341\n",
      "197 197\n",
      "197 197\n",
      "163 163\n",
      "163 163\n",
      "918 918\n",
      "918 918\n",
      "137 137\n",
      "137 137\n",
      "110 110\n",
      "110 110\n",
      "708 708\n",
      "708 708\n",
      "104 104\n",
      "104 104\n",
      "87 87\n",
      "87 87\n",
      "Train 16\n",
      "Test 14 Counter({'O': 17405, 'I-ADDRESS': 57, 'I-PHONE': 29, 'B-NAME': 26, 'I-NAME': 25, 'B-PHONE': 19, 'B-EMAIL': 19, 'I-DOB': 14, 'B-NATIONALITY': 10, 'B-ADDRESS': 9, 'B-DOB': 5, 'B-GENDER': 5, 'B-ETHNICITY': 2, 'B-AGE': 1})\n",
      "Dev 14 Counter({'O': 14804, 'I-ADDRESS': 78, 'I-PHONE': 42, 'B-PHONE': 28, 'I-NAME': 25, 'B-NAME': 22, 'B-EMAIL': 20, 'B-ADDRESS': 12, 'I-DOB': 10, 'B-NATIONALITY': 6, 'B-DOB': 5, 'B-GENDER': 2, 'B-AGE': 2, 'B-ETHNICITY': 1})\n",
      "5164 5164\n",
      "5164 5164\n",
      "714 714\n",
      "714 714\n",
      "612 612\n",
      "612 612\n",
      "2621 2621\n",
      "2621 2621\n",
      "366 366\n",
      "366 366\n",
      "311 311\n",
      "311 311\n",
      "1774 1774\n",
      "1774 1774\n",
      "245 245\n",
      "245 245\n",
      "211 211\n",
      "211 211\n",
      "1353 1353\n",
      "1353 1353\n",
      "187 187\n",
      "187 187\n",
      "161 161\n",
      "161 161\n",
      "925 925\n",
      "925 925\n",
      "130 130\n",
      "130 130\n",
      "110 110\n",
      "110 110\n",
      "716 716\n",
      "716 716\n",
      "99 99\n",
      "99 99\n",
      "84 84\n",
      "84 84\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    doc_Getter = DocumentGetter(df)\n",
    "    doc_Getter.split_docs()\n",
    "    doc_Getter.create_files()\n",
    "    for sl in SENTENCE_LENGTHS:\n",
    "        create_file('train', sl, str(i))\n",
    "        create_file('test', sl, str(i))\n",
    "        create_file('dev', sl, str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715 715\n",
      "715 715\n"
     ]
    }
   ],
   "source": [
    "create_file('train', SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 97\n",
      "97 97\n"
     ]
    }
   ],
   "source": [
    "create_file('test', SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 87\n",
      "87 87\n"
     ]
    }
   ],
   "source": [
    "create_file('dev', SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
